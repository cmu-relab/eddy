package eddy.lang.analysis;

import java.io.File;
import java.io.PrintWriter;
import java.util.ArrayList;
import java.util.List;
import java.util.TreeMap;
import java.util.TreeSet;

import org.semanticweb.owlapi.model.IRI;
import org.semanticweb.owlapi.util.SimpleIRIMapper;

import eddy.lang.Action;
import eddy.lang.Policy;
import eddy.lang.Role;
import eddy.lang.Role.Type;
import eddy.lang.Rule;
import eddy.lang.Rule.Modality;
import eddy.lang.parser.Compilation;
import eddy.lang.parser.CompilationProperties;
import eddy.lang.parser.Compiler;
import eddy.lang.parser.Logger;
import eddy.lang.parser.ParseException;

/**
 * Applies the limitation principle across two actions. This implementation
 * identifies all source rights (e.g., collection rights) and generates rights
 * for the target actions with the same role descriptions. Satisfiability is
 * checked by assuring that all original target rights are subsumed by the new
 * target rights generated by this principle. Subsumption is checked by ensuring
 * the set of original target interpretations is contained in the set of new
 * target interpretations.
 * 
 * The new target rights generated by this principle are not preserved within the
 * original policy and are discarded after this analysis completes.
 * 
 * @author Travis Breaux
 *
 */

public class LimitationPrinciple implements CompilationProperties {
	public class Violation implements Comparable<Violation> {
		public final TreeSet<String> source;
		public final TreeSet<String> target;
		public final Action action;
		public final String id;
		public final TreeSet<Rule> violators;
		public final TreeSet<Rule> relaxables;
		
		public Violation(LimitationPrinciple principle, String id, Action action, TreeSet<Rule> violators, TreeSet<Rule> relaxables) {
			this.source = new TreeSet<String>(principle.source);
			this.target = new TreeSet<String>(principle.target);
			this.id = id;
			this.action = action;
			this.violators = violators;
			this.relaxables = relaxables;
		}
		public int compareTo(Violation v) {
			return id.compareTo(v.id);
		}
		public boolean equals(Violation v) {
			return compareTo(v) == 0;
		}
		
		public String toString() {
			TreeSet<String> rIDs = new TreeSet<String>();
			for (Rule r : violators) {
				rIDs.add(r.id);
			}
			TreeSet<String> xIDs = new TreeSet<String>();
			for (Rule r : relaxables) {
				xIDs.add(r.id);
			}
			String s = target.toString() + "-limitation violated by " + rIDs.toString() + 
					", relaxables: "+ xIDs.toString();
			return s;
		}
	}
	class Worker implements Runnable {
		private Extension extComp;
		private ArrayList<Violation> violations = null;
		private int index;
		private LimitationPrinciple principle;
		
		public Worker(LimitationPrinciple principle) {
			this.principle = principle;
		}
		public void run() {
			this.violations = new ArrayList<Violation>();

			// find all the target right interpretations
			TreeMap<Rule,TreeSet<String>> targets = ExtensionCalculator.findExtension(extComp, targetRights);
			TreeSet<String> targetIDs = new TreeSet<String>();
			for (TreeSet<String> set : targets.values()) {
				targetIDs.addAll(set);
			}
			int targetSize = targetIDs.size();
			
			// final all the limitation right interpretations
			TreeMap<Rule,TreeSet<String>> limits = ExtensionCalculator.findExtension(extComp, limitRights);
			TreeSet<String> limitIDs = new TreeSet<String>();
			for (TreeSet<String> set : limits.values()) {
				limitIDs.addAll(set);
			}
			int limitSize = limitIDs.size();
			
			// find all rules not subsumed by the limitations
			targetIDs.removeAll(limitIDs);
			TreeMap<String,TreeSet<Rule>> rules = ExtensionCalculator.findRules(extComp, targetIDs);

			for (String id : rules.keySet()) {
				Action action = extComp.getAction(id);
				Role obj = action.getRole(Type.OBJECT);
				Role src = action.getRole(Type.SOURCE);
				
				// find source rules using generalization of non-limited, violating interpretations
				TreeSet<Rule> sources = new TreeSet<Rule>();
				for (String act : source) {
					Action generic = new Action(act);
					generic.add(obj);
					generic.add(src);
					TreeMap<String,TreeSet<Rule>> map = ExtensionCalculator.findRules(extComp, generic);
					for (TreeSet<Rule> values : map.values()) {
						sources.addAll(values);
					}
				}
				
				// filter violating rules by permissions and obligations
				TreeSet<Rule> violators = new TreeSet<Rule>();
				for (Rule r : rules.get(id)) {
					if (r.modality == Modality.PERMISSION || r.modality == Modality.OBLIGATION) {
						violators.add(r);
					}
				}
				
				Violation v = new Violation(principle, id, action, violators, sources);
				violations.add(v);
			}
			logger.log(Logger.DEBUG, "Found " + violations.size() + " violation(s) among " + targetSize + " targets and " + limitSize + " limits ");

		}
	}
	private static File basePolicy = null;
	public static void setOntologyBasePolicy(String path) {
		basePolicy = new File(path);
	}
	private final TreeSet<String> source = new TreeSet<String>();
	private final TreeSet<String> target = new TreeSet<String>();
	private Compilation extComp;
	private Logger logger = new Logger(new PrintWriter(System.err), Logger.WARN, this.getClass().getName() + ": ");
	private int threadCount = 3;
	private int blockSize = 1000;
	
	private ArrayList<Violation> violations = new ArrayList<Violation>();
	
	private ArrayList<Rule> targetRights = new ArrayList<Rule>();
	
	private ArrayList<Rule> limitRights = new ArrayList<Rule>();

	public LimitationPrinciple() {
		return;
	}

	public void addSource(String action) {
		source.add(action);
	}
	
	public void addTarget(String action) {
		target.add(action);
	}
	
	public ArrayList<Violation> analyze(Compilation comp) throws ParseException {
		// reset the violations for this analysis
		this.violations.clear();
		
		// identify all the source rights
		Policy policy = comp.getPolicy();
		ArrayList<Rule> sourceRights = new ArrayList<Rule>();
		ArrayList<Action> targetActions = new ArrayList<Action>();
		targetRights.clear();
		for (Rule rule : policy.rules()) {
			// skip all rules that are not permissions, or implied permissions
			if (rule.modality != Modality.PERMISSION && rule.modality != Modality.OBLIGATION) {
				continue;
			}
			if (source.contains(rule.action.name)) {
				sourceRights.add(rule);
			}
			else if (target.contains(rule.action.name)) {
				targetRights.add(rule);
				targetActions.add(rule.action.clone());
			}
		}
		logger.log(Logger.DEBUG, "Identified " + sourceRights.size() + " source and " + targetRights.size() + " target rights");
		
		// create a cloned policy extended with the limitation rights
		Policy extPolicy = policy.clone();
		int counter = 0;
		limitRights.clear();
		for (Rule rule : sourceRights) {
			for (String name : target) {
				Rule limit = new Rule("l" + counter, rule.modality, new Action(name), rule.only);
				for (Role role : rule.action.roles()) {
					limit.action.add(role);
				}
				limitRights.add(limit);
				extPolicy.add(limit);
				counter++;
			}
		}
		logger.log(Logger.DEBUG, "Computed " + limitRights.size() + " limiting rights");
		
		// compile the extended policy for analysis
		Compiler compiler = new Compiler();
		// load the upper ontology
		if (basePolicy != null) {
			IRI docIRI = IRI.create("http://gaius.isri.cmu.edu/2011/8/policy-base.owl");
			SimpleIRIMapper mapper = new SimpleIRIMapper(docIRI, IRI.create(basePolicy));
			compiler.getManager().addIRIMapper(mapper);
		}
		this.extComp = compiler.compile(extPolicy);
		
		// compute the extension based on the target actions, only
		ExtensionCalculator calc = new ExtensionCalculator();
		ArrayList<Action> actions = calc.compute(comp, targetActions);
		logger.log(Logger.DEBUG, "Calculated " + actions.size() + " actions in the extensions");
		
		// separate the actions into work blocks
		ArrayList<List<Action>> blocks = new ArrayList<List<Action>>();
		for (int i = 0; i < actions.size(); i += blockSize) {
			blocks.add(actions.subList(i, Math.min(actions.size(), i + blockSize)));
		}
		
		// distribute blocks to workers
		distribute(blocks, extComp);
		
		extComp.getProperties().setProperty(LIMIT_COMPUTED, "yes");
		extComp.getProperties().setProperty(LIMIT_SOURCE, "" + source);
		extComp.getProperties().setProperty(LIMIT_TARGET, "" + target);
		extComp.getProperties().setProperty(LIMIT_RIGHTS, "" + limitRights.size());
		extComp.getProperties().setProperty(LIMIT_VIOLATIONS, "" + violations.size());
		return new ArrayList<Violation>(violations);
	}
	
	private void distribute(ArrayList<List<Action>> blocks, Compilation comp) {
		Worker[] worker = new Worker[threadCount];
		Thread[] thread = new Thread[threadCount];
		
		// initialize workers with shared list
		for (int i = 0; i < worker.length; i++) {
			worker[i] = new Worker(this);
		}
		
		logger.log(Logger.DEBUG, "Dispatching " + blocks.size() + " work blocks to " + threadCount + " workers...");
		for (int i = 0; i < thread.length; i++) {
			thread[i] = new Thread();
		}

		// begin distribution of blocks to workers
		int index = 0;
		boolean running = true;
		while (running) {
			running = false;
			for (int i = 0; i < thread.length; i++) {
				if (thread[i] == null) {
					continue;
				}
				else if (thread[i].isAlive()) {
					running = true;
				}
				else {
					// check if this worker has any uncollected work
					if (worker[i].violations != null) {
						logger.log(Logger.DEBUG, "Received block " + worker[i].index + " with " + worker[i].violations.size() + " violations");
						this.violations.addAll(worker[i].violations);
						worker[i].violations = null;
					}
					
					// start a new thread for any remaining blocks
					if (index < blocks.size()) {
						List<Action> block = blocks.get(index);
						int counter = index * blockSize;
						worker[i].index = index;
						worker[i].extComp = ExtensionCalculator.extend(comp, block, counter);
						index++;
						thread[i] = new Thread(worker[i]);
						thread[i].start();
						running = true;
					}
					else {
						thread[i] = null;
					}
				}
			}
			try {
				Thread.sleep(1000);
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
		}
	}
	
	public Compilation getExtendedCompilation() {
		return extComp;
	}
}
